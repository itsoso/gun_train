"""
æ€§èƒ½ä¼˜åŒ–æ¨¡å—
GPUæ‰¹å¤„ç†ã€å¤šçº¿ç¨‹ä¼˜åŒ–ã€å†…å­˜ç®¡ç†
"""

import cv2
import numpy as np
from typing import Dict, List, Optional, Tuple, Callable, Any
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import threading
import queue
import time
import logging
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import multiprocessing as mp
from collections import deque
import gc

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    # å¤„ç†é€Ÿåº¦
    fps: float = 0.0
    frames_processed: int = 0
    avg_processing_time_ms: float = 0.0
    max_processing_time_ms: float = 0.0
    min_processing_time_ms: float = float('inf')
    
    # é˜Ÿåˆ—çŠ¶æ€
    input_queue_size: int = 0
    output_queue_size: int = 0
    
    # èµ„æºä½¿ç”¨
    cpu_usage_percent: float = 0.0
    memory_usage_mb: float = 0.0
    gpu_usage_percent: float = 0.0
    gpu_memory_mb: float = 0.0
    
    # ååé‡
    throughput_per_second: float = 0.0
    dropped_frames: int = 0
    
    # æ—¶é—´ç»Ÿè®¡
    uptime_seconds: float = 0.0
    start_time: Optional[datetime] = None


class FrameBatcher:
    """å¸§æ‰¹å¤„ç†å™¨ - å°†å¤šå¸§æ‰“åŒ…æˆæ‰¹æ¬¡è¿›è¡Œå¤„ç†"""
    
    def __init__(
        self,
        batch_size: int = 8,
        max_wait_time: float = 0.1,  # æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        input_shape: Tuple[int, int, int] = (480, 640, 3)
    ):
        """
        Args:
            batch_size: æ‰¹å¤§å°
            max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´
            input_shape: è¾“å…¥å¸§å½¢çŠ¶
        """
        self.batch_size = batch_size
        self.max_wait_time = max_wait_time
        self.input_shape = input_shape
        
        self.frame_buffer: List[Tuple[Any, np.ndarray]] = []  # (metadata, frame)
        self.buffer_lock = threading.Lock()
        self.last_batch_time = time.time()
        
        # ç»Ÿè®¡
        self.total_batches = 0
        self.total_frames = 0
    
    def add_frame(self, frame: np.ndarray, metadata: Any = None) -> Optional[Tuple[List[Any], np.ndarray]]:
        """
        æ·»åŠ å¸§åˆ°æ‰¹æ¬¡ç¼“å†²åŒº
        
        Args:
            frame: å›¾åƒå¸§
            metadata: å…ƒæ•°æ®
            
        Returns:
            å¦‚æœæ‰¹æ¬¡å·²æ»¡æˆ–è¶…æ—¶ï¼Œè¿”å›(å…ƒæ•°æ®åˆ—è¡¨, æ‰¹æ¬¡æ•°ç»„)ï¼Œå¦åˆ™è¿”å›None
        """
        with self.buffer_lock:
            # è°ƒæ•´å¸§å¤§å°
            if frame.shape != self.input_shape:
                frame = cv2.resize(frame, (self.input_shape[1], self.input_shape[0]))
            
            self.frame_buffer.append((metadata, frame))
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿”å›æ‰¹æ¬¡
            current_time = time.time()
            should_return = (
                len(self.frame_buffer) >= self.batch_size or
                (len(self.frame_buffer) > 0 and 
                 current_time - self.last_batch_time >= self.max_wait_time)
            )
            
            if should_return:
                return self._flush_buffer()
            
            return None
    
    def _flush_buffer(self) -> Tuple[List[Any], np.ndarray]:
        """åˆ·æ–°ç¼“å†²åŒºå¹¶è¿”å›æ‰¹æ¬¡"""
        metadata_list = [item[0] for item in self.frame_buffer]
        frames = np.array([item[1] for item in self.frame_buffer])
        
        self.frame_buffer.clear()
        self.last_batch_time = time.time()
        self.total_batches += 1
        self.total_frames += len(frames)
        
        return metadata_list, frames
    
    def flush(self) -> Optional[Tuple[List[Any], np.ndarray]]:
        """å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒº"""
        with self.buffer_lock:
            if self.frame_buffer:
                return self._flush_buffer()
            return None
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_batches": self.total_batches,
            "total_frames": self.total_frames,
            "avg_batch_size": self.total_frames / max(self.total_batches, 1),
            "buffer_size": len(self.frame_buffer)
        }


class ThreadPoolManager:
    """çº¿ç¨‹æ± ç®¡ç†å™¨"""
    
    def __init__(
        self,
        max_workers: int = None,
        thread_name_prefix: str = "worker"
    ):
        """
        Args:
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼Œé»˜è®¤ä¸ºCPUæ ¸å¿ƒæ•°
            thread_name_prefix: çº¿ç¨‹åå‰ç¼€
        """
        self.max_workers = max_workers or mp.cpu_count()
        self.thread_name_prefix = thread_name_prefix
        
        self.executor = ThreadPoolExecutor(
            max_workers=self.max_workers,
            thread_name_prefix=thread_name_prefix
        )
        
        self.pending_tasks = 0
        self.completed_tasks = 0
        self.failed_tasks = 0
        self.task_lock = threading.Lock()
        
        logger.info(f"ğŸ”§ çº¿ç¨‹æ± åˆå§‹åŒ–: {self.max_workers} ä¸ªå·¥ä½œçº¿ç¨‹")
    
    def submit(self, fn: Callable, *args, **kwargs):
        """æäº¤ä»»åŠ¡"""
        with self.task_lock:
            self.pending_tasks += 1
        
        future = self.executor.submit(self._wrapped_fn, fn, *args, **kwargs)
        return future
    
    def _wrapped_fn(self, fn: Callable, *args, **kwargs):
        """åŒ…è£…å‡½æ•°ç”¨äºç»Ÿè®¡"""
        try:
            result = fn(*args, **kwargs)
            with self.task_lock:
                self.completed_tasks += 1
                self.pending_tasks -= 1
            return result
        except Exception as e:
            with self.task_lock:
                self.failed_tasks += 1
                self.pending_tasks -= 1
            raise e
    
    def map(self, fn: Callable, iterables, timeout: float = None):
        """æ‰¹é‡æäº¤ä»»åŠ¡"""
        return self.executor.map(fn, iterables, timeout=timeout)
    
    def shutdown(self, wait: bool = True):
        """å…³é—­çº¿ç¨‹æ± """
        self.executor.shutdown(wait=wait)
        logger.info("ğŸ”§ çº¿ç¨‹æ± å·²å…³é—­")
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "max_workers": self.max_workers,
            "pending_tasks": self.pending_tasks,
            "completed_tasks": self.completed_tasks,
            "failed_tasks": self.failed_tasks
        }


class AsyncFrameProcessor:
    """å¼‚æ­¥å¸§å¤„ç†å™¨"""
    
    def __init__(
        self,
        process_fn: Callable[[np.ndarray], Any],
        num_workers: int = 4,
        input_queue_size: int = 100,
        output_queue_size: int = 100
    ):
        """
        Args:
            process_fn: å¤„ç†å‡½æ•°
            num_workers: å·¥ä½œçº¿ç¨‹æ•°
            input_queue_size: è¾“å…¥é˜Ÿåˆ—å¤§å°
            output_queue_size: è¾“å‡ºé˜Ÿåˆ—å¤§å°
        """
        self.process_fn = process_fn
        self.num_workers = num_workers
        
        self.input_queue = queue.Queue(maxsize=input_queue_size)
        self.output_queue = queue.Queue(maxsize=output_queue_size)
        
        self.workers: List[threading.Thread] = []
        self.is_running = False
        
        # æ€§èƒ½æŒ‡æ ‡
        self.metrics = PerformanceMetrics(start_time=datetime.now())
        self.processing_times: deque = deque(maxlen=100)
    
    def start(self):
        """å¯åŠ¨å¤„ç†å™¨"""
        if self.is_running:
            return
        
        self.is_running = True
        self.metrics.start_time = datetime.now()
        
        for i in range(self.num_workers):
            worker = threading.Thread(
                target=self._worker_loop,
                name=f"frame_processor_{i}",
                daemon=True
            )
            worker.start()
            self.workers.append(worker)
        
        logger.info(f"ğŸš€ å¼‚æ­¥å¸§å¤„ç†å™¨å¯åŠ¨: {self.num_workers} ä¸ªå·¥ä½œçº¿ç¨‹")
    
    def stop(self):
        """åœæ­¢å¤„ç†å™¨"""
        self.is_running = False
        
        # å‘é€åœæ­¢ä¿¡å·
        for _ in self.workers:
            try:
                self.input_queue.put(None, timeout=0.1)
            except queue.Full:
                pass
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        for worker in self.workers:
            worker.join(timeout=2)
        
        self.workers.clear()
        logger.info("â¹ï¸ å¼‚æ­¥å¸§å¤„ç†å™¨å·²åœæ­¢")
    
    def _worker_loop(self):
        """å·¥ä½œçº¿ç¨‹å¾ªç¯"""
        while self.is_running:
            try:
                item = self.input_queue.get(timeout=0.1)
                
                if item is None:  # åœæ­¢ä¿¡å·
                    break
                
                frame_id, frame, metadata = item
                
                # å¤„ç†å¸§
                start_time = time.time()
                try:
                    result = self.process_fn(frame)
                    success = True
                except Exception as e:
                    result = None
                    success = False
                    logger.error(f"å¤„ç†å¸§æ—¶å‡ºé”™: {e}")
                
                processing_time = (time.time() - start_time) * 1000
                self.processing_times.append(processing_time)
                
                # æ›´æ–°æŒ‡æ ‡
                self.metrics.frames_processed += 1
                self.metrics.max_processing_time_ms = max(
                    self.metrics.max_processing_time_ms, processing_time
                )
                self.metrics.min_processing_time_ms = min(
                    self.metrics.min_processing_time_ms, processing_time
                )
                
                # æ”¾å…¥è¾“å‡ºé˜Ÿåˆ—
                output_item = (frame_id, result, metadata, success, processing_time)
                try:
                    self.output_queue.put(output_item, timeout=0.1)
                except queue.Full:
                    self.metrics.dropped_frames += 1
                
            except queue.Empty:
                continue
    
    def submit(self, frame: np.ndarray, frame_id: int = None, metadata: Any = None):
        """
        æäº¤å¸§è¿›è¡Œå¤„ç†
        
        Args:
            frame: å›¾åƒå¸§
            frame_id: å¸§ID
            metadata: å…ƒæ•°æ®
        """
        if frame_id is None:
            frame_id = self.metrics.frames_processed
        
        try:
            self.input_queue.put((frame_id, frame, metadata), timeout=0.01)
        except queue.Full:
            self.metrics.dropped_frames += 1
    
    def get_result(self, timeout: float = 0.1) -> Optional[Tuple]:
        """
        è·å–å¤„ç†ç»“æœ
        
        Returns:
            (frame_id, result, metadata, success, processing_time_ms)
        """
        try:
            return self.output_queue.get(timeout=timeout)
        except queue.Empty:
            return None
    
    def get_metrics(self) -> PerformanceMetrics:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        if self.processing_times:
            self.metrics.avg_processing_time_ms = np.mean(list(self.processing_times))
        
        self.metrics.input_queue_size = self.input_queue.qsize()
        self.metrics.output_queue_size = self.output_queue.qsize()
        
        if self.metrics.start_time:
            elapsed = (datetime.now() - self.metrics.start_time).total_seconds()
            self.metrics.uptime_seconds = elapsed
            if elapsed > 0:
                self.metrics.fps = self.metrics.frames_processed / elapsed
                self.metrics.throughput_per_second = self.metrics.frames_processed / elapsed
        
        return self.metrics


class GPUBatchProcessor:
    """GPUæ‰¹å¤„ç†å™¨ï¼ˆä½¿ç”¨OpenCVçš„CUDAåç«¯ï¼‰"""
    
    def __init__(
        self,
        batch_size: int = 16,
        use_gpu: bool = True
    ):
        """
        Args:
            batch_size: æ‰¹å¤§å°
            use_gpu: æ˜¯å¦ä½¿ç”¨GPU
        """
        self.batch_size = batch_size
        self.use_gpu = use_gpu and self._check_gpu_available()
        
        self.batcher = FrameBatcher(batch_size=batch_size)
        
        if self.use_gpu:
            logger.info("ğŸ® GPUåŠ é€Ÿå·²å¯ç”¨")
        else:
            logger.info("ğŸ’» ä½¿ç”¨CPUå¤„ç†")
    
    def _check_gpu_available(self) -> bool:
        """æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨"""
        try:
            # æ£€æŸ¥OpenCV CUDAæ”¯æŒ
            if cv2.cuda.getCudaEnabledDeviceCount() > 0:
                return True
        except:
            pass
        
        # æ£€æŸ¥æ˜¯å¦æœ‰CUDAè®¾å¤‡
        try:
            import torch
            return torch.cuda.is_available()
        except:
            pass
        
        return False
    
    def preprocess_batch(self, frames: np.ndarray) -> np.ndarray:
        """
        æ‰¹é‡é¢„å¤„ç†
        
        Args:
            frames: æ‰¹æ¬¡å¸§ (N, H, W, C)
            
        Returns:
            é¢„å¤„ç†åçš„å¸§
        """
        if self.use_gpu:
            try:
                # ä½¿ç”¨GPUè¿›è¡Œé¢„å¤„ç†
                processed = []
                for frame in frames:
                    gpu_frame = cv2.cuda_GpuMat()
                    gpu_frame.upload(frame)
                    
                    # è°ƒæ•´å¤§å°
                    gpu_resized = cv2.cuda.resize(gpu_frame, (640, 480))
                    
                    # å½’ä¸€åŒ–
                    processed.append(gpu_resized.download())
                
                return np.array(processed)
            except Exception as e:
                logger.warning(f"GPUå¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}")
        
        # CPUå¤„ç†
        processed = []
        for frame in frames:
            resized = cv2.resize(frame, (640, 480))
            processed.append(resized)
        
        return np.array(processed)
    
    def process_batch(
        self,
        frames: np.ndarray,
        process_fn: Callable[[np.ndarray], Any]
    ) -> List[Any]:
        """
        æ‰¹é‡å¤„ç†
        
        Args:
            frames: æ‰¹æ¬¡å¸§
            process_fn: å¤„ç†å‡½æ•°
            
        Returns:
            å¤„ç†ç»“æœåˆ—è¡¨
        """
        # é¢„å¤„ç†
        preprocessed = self.preprocess_batch(frames)
        
        # å¤„ç†
        results = []
        for frame in preprocessed:
            result = process_fn(frame)
            results.append(result)
        
        return results


class MemoryManager:
    """å†…å­˜ç®¡ç†å™¨"""
    
    def __init__(
        self,
        max_memory_mb: int = 1024,
        gc_threshold: float = 0.8
    ):
        """
        Args:
            max_memory_mb: æœ€å¤§å†…å­˜ä½¿ç”¨ï¼ˆMBï¼‰
            gc_threshold: GCè§¦å‘é˜ˆå€¼
        """
        self.max_memory_mb = max_memory_mb
        self.gc_threshold = gc_threshold
        
        # å¯¹è±¡æ± 
        self.frame_pool: List[np.ndarray] = []
        self.pool_size = 50
        self.pool_lock = threading.Lock()
        
        # ç»Ÿè®¡
        self.allocations = 0
        self.deallocations = 0
        self.gc_runs = 0
    
    def get_frame_buffer(self, shape: Tuple[int, int, int] = (480, 640, 3)) -> np.ndarray:
        """
        ä»æ± ä¸­è·å–å¸§ç¼“å†²åŒº
        
        Args:
            shape: å¸§å½¢çŠ¶
            
        Returns:
            å¸§ç¼“å†²åŒº
        """
        with self.pool_lock:
            if self.frame_pool:
                buffer = self.frame_pool.pop()
                if buffer.shape == shape:
                    self.allocations += 1
                    return buffer
            
            # åˆ›å»ºæ–°ç¼“å†²åŒº
            self.allocations += 1
            return np.zeros(shape, dtype=np.uint8)
    
    def release_frame_buffer(self, buffer: np.ndarray):
        """
        é‡Šæ”¾å¸§ç¼“å†²åŒºå›æ± 
        
        Args:
            buffer: å¸§ç¼“å†²åŒº
        """
        with self.pool_lock:
            if len(self.frame_pool) < self.pool_size:
                self.frame_pool.append(buffer)
            self.deallocations += 1
    
    def get_memory_usage(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨ï¼ˆMBï¼‰"""
        import psutil
        process = psutil.Process()
        return process.memory_info().rss / 1024 / 1024
    
    def check_and_gc(self):
        """æ£€æŸ¥å¹¶æ‰§è¡ŒGC"""
        current_usage = self.get_memory_usage()
        
        if current_usage > self.max_memory_mb * self.gc_threshold:
            gc.collect()
            self.gc_runs += 1
            
            new_usage = self.get_memory_usage()
            logger.info(f"ğŸ§¹ GCæ‰§è¡Œ: {current_usage:.1f}MB -> {new_usage:.1f}MB")
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "memory_usage_mb": self.get_memory_usage(),
            "max_memory_mb": self.max_memory_mb,
            "pool_size": len(self.frame_pool),
            "allocations": self.allocations,
            "deallocations": self.deallocations,
            "gc_runs": self.gc_runs
        }


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, window_size: int = 100):
        """
        Args:
            window_size: ç»Ÿè®¡çª—å£å¤§å°
        """
        self.window_size = window_size
        
        self.frame_times: deque = deque(maxlen=window_size)
        self.processing_times: deque = deque(maxlen=window_size)
        
        self.start_time = time.time()
        self.total_frames = 0
    
    def record_frame(self, processing_time_ms: float):
        """
        è®°å½•å¸§å¤„ç†æ—¶é—´
        
        Args:
            processing_time_ms: å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        """
        current_time = time.time()
        self.frame_times.append(current_time)
        self.processing_times.append(processing_time_ms)
        self.total_frames += 1
    
    def get_fps(self) -> float:
        """è·å–å®æ—¶FPS"""
        if len(self.frame_times) < 2:
            return 0.0
        
        time_span = self.frame_times[-1] - self.frame_times[0]
        if time_span <= 0:
            return 0.0
        
        return (len(self.frame_times) - 1) / time_span
    
    def get_avg_processing_time(self) -> float:
        """è·å–å¹³å‡å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰"""
        if not self.processing_times:
            return 0.0
        return np.mean(list(self.processing_times))
    
    def get_p95_processing_time(self) -> float:
        """è·å–P95å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰"""
        if not self.processing_times:
            return 0.0
        return np.percentile(list(self.processing_times), 95)
    
    def get_summary(self) -> Dict:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        return {
            "fps": round(self.get_fps(), 2),
            "avg_processing_time_ms": round(self.get_avg_processing_time(), 2),
            "p95_processing_time_ms": round(self.get_p95_processing_time(), 2),
            "total_frames": self.total_frames,
            "uptime_seconds": round(time.time() - self.start_time, 1)
        }


# å·¥å‚å‡½æ•°
def create_optimized_processor(
    process_fn: Callable,
    num_workers: int = 4,
    batch_size: int = 8,
    use_gpu: bool = True
) -> AsyncFrameProcessor:
    """
    åˆ›å»ºä¼˜åŒ–çš„å¸§å¤„ç†å™¨
    
    Args:
        process_fn: å¤„ç†å‡½æ•°
        num_workers: å·¥ä½œçº¿ç¨‹æ•°
        batch_size: æ‰¹å¤§å°
        use_gpu: æ˜¯å¦ä½¿ç”¨GPU
        
    Returns:
        å¼‚æ­¥å¸§å¤„ç†å™¨
    """
    # åˆ›å»ºGPUæ‰¹å¤„ç†å™¨
    gpu_processor = GPUBatchProcessor(batch_size=batch_size, use_gpu=use_gpu)
    
    # åŒ…è£…å¤„ç†å‡½æ•°
    def optimized_process(frame):
        # è¿™é‡Œå¯ä»¥æ·»åŠ GPUé¢„å¤„ç†
        return process_fn(frame)
    
    # åˆ›å»ºå¼‚æ­¥å¤„ç†å™¨
    processor = AsyncFrameProcessor(
        process_fn=optimized_process,
        num_workers=num_workers
    )
    
    return processor


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æµ‹è¯•å¼‚æ­¥å¸§å¤„ç†å™¨
    def dummy_process(frame):
        """æ¨¡æ‹Ÿå¤„ç†å‡½æ•°"""
        time.sleep(0.01)  # æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
        return {"shape": frame.shape, "mean": np.mean(frame)}
    
    processor = AsyncFrameProcessor(
        process_fn=dummy_process,
        num_workers=4
    )
    
    processor.start()
    
    # æäº¤å¸§
    for i in range(100):
        frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        processor.submit(frame, frame_id=i)
    
    # è·å–ç»“æœ
    results_count = 0
    start = time.time()
    
    while results_count < 100:
        result = processor.get_result(timeout=1.0)
        if result:
            results_count += 1
    
    elapsed = time.time() - start
    
    # æ‰“å°ç»Ÿè®¡
    metrics = processor.get_metrics()
    print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
    print(f"  å¤„ç†å¸§æ•°: {metrics.frames_processed}")
    print(f"  FPS: {metrics.fps:.2f}")
    print(f"  å¹³å‡å¤„ç†æ—¶é—´: {metrics.avg_processing_time_ms:.2f}ms")
    print(f"  ä¸¢å¸§æ•°: {metrics.dropped_frames}")
    
    processor.stop()

